{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза «мешка слов». Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать «мешком ингредиентов», потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные «темы». Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули *json* и *gensim*. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "*pip install gensim*\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (cuisine) и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Запомнил твой рот своим хуем.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "with open('1chan_lines.txt','r', encoding=\"utf-8\") as f:\n",
    "    lines = [l.rstrip() for l in f.readlines()]\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая, и целиком помещается в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.030*\"ты\" + 0.024*\"почему\" + 0.022*\"зачем\" + 0.018*\"мать\" + 0.017*\"твоя\" + 0.014*\"в\" + 0.011*\"и\" + 0.010*\"сосет\" + 0.006*\"тут\" + 0.006*\"как\" + 0.006*\"на\" + 0.005*\"ротешник\" + 0.005*\"сука\" + 0.005*\"слона\" + 0.005*\"себе\" + 0.004*\"рта\" + 0.004*\"поссал\" + 0.004*\"всегда\" + 0.004*\"твоего\" + 0.004*\"у\"'),\n",
       " (1,\n",
       "  '0.014*\"на\" + 0.014*\"с\" + 0.011*\"и\" + 0.010*\"не\" + 0.008*\"нет\" + 0.007*\"в\" + 0.007*\"я\" + 0.007*\"как\" + 0.006*\"s\" + 0.005*\"для\" + 0.005*\"а\" + 0.005*\"он\" + 0.004*\"хуй\" + 0.004*\"но\" + 0.004*\"ну\" + 0.004*\"рот\" + 0.004*\"иди\" + 0.004*\"это\" + 0.004*\"1chanca\" + 0.004*\"о\"'),\n",
       " (2,\n",
       "  '0.013*\"это\" + 0.010*\"и\" + 0.010*\"на\" + 0.009*\"ты\" + 0.008*\"the\" + 0.008*\"в\" + 0.007*\"у\" + 0.007*\"а\" + 0.006*\"что\" + 0.005*\"я\" + 0.005*\"ник\" + 0.005*\"не\" + 0.004*\"зачем\" + 0.004*\"тут\" + 0.004*\"party\" + 0.004*\"по\" + 0.004*\"свой\" + 0.004*\"назови\" + 0.004*\"же\" + 0.004*\"но\"'),\n",
       " (3,\n",
       "  '0.059*\"не\" + 0.025*\"и\" + 0.014*\"я\" + 0.012*\"на\" + 0.012*\"а\" + 0.012*\"в\" + 0.010*\"ты\" + 0.010*\"что\" + 0.009*\"он\" + 0.007*\"либертарианец\" + 0.007*\"но\" + 0.007*\"бы\" + 0.006*\"человек\" + 0.005*\"да\" + 0.005*\"почему\" + 0.005*\"дыркутский\" + 0.005*\"мне\" + 0.005*\"ну\" + 0.005*\"с\" + 0.004*\"то\"'),\n",
       " (4,\n",
       "  '0.017*\"ты\" + 0.015*\"го\" + 0.015*\"а\" + 0.013*\"на\" + 0.012*\"не\" + 0.011*\"стульчак\" + 0.011*\"выпиливаться\" + 0.010*\"с\" + 0.009*\"у\" + 0.007*\"фк\" + 0.007*\"скот\" + 0.007*\"тупорылый\" + 0.007*\"я\" + 0.007*\"все\" + 0.006*\"и\" + 0.006*\"зачем\" + 0.006*\"привет\" + 0.006*\"меня\" + 0.005*\"как\" + 0.005*\"хуй\"'),\n",
       " (5,\n",
       "  '0.022*\"в\" + 0.020*\"и\" + 0.019*\"что\" + 0.016*\"на\" + 0.013*\"я\" + 0.010*\"а\" + 0.008*\"не\" + 0.007*\"у\" + 0.006*\"все\" + 0.005*\"от\" + 0.005*\"сша\" + 0.005*\"это\" + 0.005*\"но\" + 0.005*\"правда\" + 0.005*\"голосов\" + 0.005*\"как\" + 0.004*\"там\" + 0.004*\"меня\" + 0.004*\"он\" + 0.004*\"по\"'),\n",
       " (6,\n",
       "  '0.018*\"на\" + 0.018*\"я\" + 0.018*\"а\" + 0.017*\"не\" + 0.015*\"и\" + 0.010*\"в\" + 0.010*\"что\" + 0.006*\"хуй\" + 0.006*\"мне\" + 0.005*\"за\" + 0.005*\"=\" + 0.005*\"зачем\" + 0.005*\"это\" + 0.005*\"но\" + 0.004*\"быдло\" + 0.004*\"твой\" + 0.004*\"ты\" + 0.004*\"раз\" + 0.004*\"только\" + 0.004*\"мразотная\"'),\n",
       " (7,\n",
       "  '0.031*\"ты\" + 0.016*\"не\" + 0.013*\"а\" + 0.012*\"и\" + 0.007*\"для\" + 0.007*\"почему\" + 0.006*\"еще\" + 0.006*\"с\" + 0.006*\"же\" + 0.006*\"на\" + 0.005*\"тебя\" + 0.005*\"у\" + 0.005*\"в\" + 0.005*\"все\" + 0.005*\"я\" + 0.005*\"нет\" + 0.004*\"выгребной\" + 0.004*\"ямой\" + 0.004*\"опарышами\" + 0.004*\"грязной\"'),\n",
       " (8,\n",
       "  '0.018*\"в\" + 0.012*\"это\" + 0.009*\"на\" + 0.008*\"the\" + 0.008*\"с\" + 0.008*\"же\" + 0.008*\"кто\" + 0.007*\"а\" + 0.005*\"и\" + 0.005*\"and\" + 0.005*\"we\" + 0.005*\"it\" + 0.005*\"говно\" + 0.005*\"стульчмо\" + 0.005*\"не\" + 0.005*\"но\" + 0.004*\"из\" + 0.004*\"to\" + 0.004*\"of\" + 0.004*\"are\"'),\n",
       " (9,\n",
       "  '0.041*\"в\" + 0.025*\"не\" + 0.022*\"и\" + 0.021*\"на\" + 0.018*\"ты\" + 0.010*\"но\" + 0.009*\"это\" + 0.007*\"я\" + 0.007*\"же\" + 0.006*\"здохни\" + 0.005*\"что\" + 0.005*\"твой\" + 0.005*\"рот\" + 0.005*\"так\" + 0.004*\"как\" + 0.004*\"а\" + 0.004*\"зачем\" + 0.004*\"за\" + 0.004*\"тебя\" + 0.004*\"человек\"')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "PUNCTUATION = [\"?\", \",\", \".\", \"—\", \":\", \"«\", \"»\", \"!\", \"http\", \")\", \"(\", \"[\", \"]\", \";\", \"=\", \"→\", \"/\", \"wwwyoutubecomwatch\", \"…\", \"%\" ]\n",
    "\n",
    "def clear_punctuation(l):\n",
    "    for str in PUNCTUATION:\n",
    "        l = l.replace(str, \"\")\n",
    "    return l.lower()\n",
    "\n",
    "def clear_frequents(lst):\n",
    "    pass            \n",
    "\n",
    "texts = [nltk.word_tokenize(clear_punctuation(l)) for l in lines[:1000]]\n",
    "dictionary = corpora.Dictionary(texts)                 # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов\n",
    "\n",
    "#freq_tokens = [dic2.id2token[k] for (k,v) in dic2.dfs.items() if v > 4000]\n",
    "\n",
    "def id2token(k):\n",
    "    try:\n",
    "        return dictionary.id2token[k]\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "#freq_tokens = [(dictionary.id2token[k], v) for (k, v) in dictionary.dfs.items()]\n",
    "#dictionary.dfs.items()\n",
    "#id2token(6)\n",
    "\n",
    "np.random.seed(76543)\n",
    "lda = models.LdaModel(corpus, num_topics=10, passes=5, id2word=dictionary)\n",
    "lda.show_topics(num_topics=10, num_words=20, log=False, formatted=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. \n",
    "\n",
    "\n",
    "Затем вызовите метод модели *show_topics*, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода *show_topics* указать параметр *formatted=True*, то топы ингредиентов будет удобно выводить на печать, если *formatted=False*, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 9, 8, 1, 0, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами — фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная *dfs* — это словарь, ключами которого являются id токена, а элементами — число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря *filter_tokens*, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after — размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after — суммарное количество ингредиентов в корпусе (для каждого документа вычислите число различных ингредиентов в нем и просуммируйте по всем документам) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6714, 6702)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic2 = dictionary2\n",
    "freq_tokens = [dic2.id2token[k] for (k,v) in dic2.dfs.items() if v > 4000]\n",
    "freq_tokens_ids = [dic2.token2id[x] for x in freq_tokens]\n",
    "dict_size_before = len(dic2)\n",
    "dic2.filter_tokens(bad_ids=freq_tokens_ids)\n",
    "dict_size_after = len(dic2)\n",
    "dict_size_before, dict_size_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428249, 343665)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2 = [dic2.doc2bow(text) for text in texts]\n",
    "corpus_size_before = sum([len(x) for x in corpus])\n",
    "corpus_size_after = sum([len(x) for x in corpus2])\n",
    "\n",
    "corpus_size_before, corpus_size_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))\n",
    "\n",
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictionary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом *top_topics* модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "lda2 = models.LdaModel(corpus2, num_topics=40, passes=5, id2word=dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.596629015979598"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence = np.mean([v for (k,v) in lda.top_topics(corpus)])\n",
    "coherence2 = np.mean([v for (k,v) in lda2.top_topics(corpus2)]);\n",
    "coherence, coherence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))\n",
    "        \n",
    "save_answers3(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом *get_document_topics* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 0.12812185), (31, 0.61758554), (33, 0.13866436)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.get_document_topics(corpus2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной *.alpha* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром *minimum_probability=0.01* и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.021397669),\n",
       " (1, 0.021295449),\n",
       " (2, 0.021276837),\n",
       " (3, 0.021365918),\n",
       " (4, 0.021295367),\n",
       " (5, 0.021311186),\n",
       " (6, 0.02130497),\n",
       " (7, 0.021280425),\n",
       " (8, 0.021401435),\n",
       " (9, 0.021379547),\n",
       " (10, 0.02183789),\n",
       " (11, 0.021492522),\n",
       " (12, 0.021276837),\n",
       " (13, 0.02218948),\n",
       " (14, 0.021718122),\n",
       " (15, 0.021506282),\n",
       " (16, 0.021404231),\n",
       " (17, 0.021964423),\n",
       " (18, 0.021329323),\n",
       " (19, 0.021678476),\n",
       " (20, 0.024654374),\n",
       " (21, 0.021277266),\n",
       " (22, 0.021276837),\n",
       " (23, 0.02128486),\n",
       " (24, 0.021771805),\n",
       " (25, 0.021494575),\n",
       " (26, 0.0214625),\n",
       " (27, 0.021634068),\n",
       " (28, 0.021495195),\n",
       " (29, 0.02130315),\n",
       " (30, 0.042615004),\n",
       " (31, 0.09219314),\n",
       " (32, 0.02150039),\n",
       " (33, 0.021278715),\n",
       " (34, 0.021446655),\n",
       " (35, 0.021365916),\n",
       " (36, 0.02133184),\n",
       " (37, 0.021289436),\n",
       " (38, 0.021277951),\n",
       " (39, 0.068339966)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "lda3 = models.LdaModel(corpus2, num_topics=40, alpha=1, passes=5, id2word=dic2)\n",
    "lda3.get_document_topics(corpus2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203683"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_model2 = sum([len(lda2.get_document_topics(doc, minimum_probability=0.01)) for doc in corpus2])\n",
    "count_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model3 = sum([len(lda3.get_document_topics(doc, minimum_probability=0.01)) for doc in corpus2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))\n",
    "\n",
    "save_answers4(count_model2, count_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр __alpha__ влияет на разреженность распределений тем в документах. Аналогично гиперпараметр __eta__ влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда, распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10–15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA — вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(t, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу $A$ размера темы $x$ кухни, ее элементы $a_{tc}$ — суммы $p(t|d)$ по всем документам $d$, которые отнесены к кухне $c$. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу $A$. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
