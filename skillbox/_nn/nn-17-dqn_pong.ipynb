{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BB3fZ0m7EfG8",
    "outputId": "39b1bc3d-145a-4ecb-9670-b0ae2ff26631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUk_TJQEE_hx",
    "outputId": "1cc59d43-84e8-4055-acbd-7fb4454c0e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tk3lkBo6FPsg"
   },
   "outputs": [],
   "source": [
    "ENV = gym.make(\"Pong-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGh950jFJDER"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self, size=10000):\n",
    "        self.size = size\n",
    "        self.buffer = deque()\n",
    "\n",
    "    def add(self, s, a, r, s2, t):\n",
    "        s = np.stack((s[0], s[1], s[2], s[3]), axis=2)\n",
    "        s2 = np.stack((s2[0], s2[1], s2[2], s2[3]), axis=2)\n",
    "        self.buffer.append((s, a, r, s2, t))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "SCREEN_SHAPE = (210, 160, 3)\n",
    "FOUR_FRAME_SHAPE = (84, 84, 4)\n",
    "\n",
    "import keras.layers as L\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, buffer, batch_size=32, min_buffer=10000, gamma=0.99, lr=1e-4):\n",
    "        self.buffer = buffer\n",
    "        self.min_buffer = min_buffer\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma        \n",
    "        self.model = self.build_model(lr)\n",
    "        self.target_model = self.build_model(lr)\n",
    "        self.copy_weights()\n",
    "\n",
    "    def build_model(self, lr = 0.001):\n",
    "        X = L.Input(shape = FOUR_FRAME_SHAPE)\n",
    "        x = L.Conv2D(32, 8, strides=(4,4), padding=\"same\", activation=\"relu\")(X)\n",
    "        x = L.Conv2D(64, 4, strides=(2,2), padding=\"same\", activation=\"relu\")(x)\n",
    "        x = L.Conv2D(64, 3, strides=(1,1), padding=\"same\", activation=\"relu\")(x)\n",
    "        x = L.Flatten()(x)\n",
    "        x = L.Dense(512,activation=\"relu\")(x)\n",
    "        Y = L.Dense(6, activation=None)(x)\n",
    "        model = keras.models.Model(inputs=X, outputs=Y)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.buffer.buffer) < self.min_buffer:\n",
    "            return\n",
    "        \n",
    "        states, actions, rewards, next_states, terminal = map(np.array, zip(*self.buffer.sample(self.batch_size)))\n",
    "        next_state_values = self.target_model.predict(next_states)\n",
    "        \n",
    "        next_state_action_values = np.max(next_state_values, axis=1)\n",
    "        \n",
    "        targets = self.model.predict(states)\n",
    "        \n",
    "        targets[range(self.batch_size), actions] = rewards + self.gamma * next_state_action_values * np.invert(terminal)\n",
    "        self.model.train_on_batch(states, targets)\n",
    "        \n",
    "\n",
    "    def copy_weights(self):\n",
    "        frm = self.model\n",
    "        to = self.target_model\n",
    "        for l_target, l_src in zip(to.layers, frm.layers):\n",
    "            l_target.set_weights(l_src.get_weights())\n",
    "\n",
    "    def predict(self, x):\n",
    "        states = np.stack((x[0], x[1], x[2], x[3]), axis=2)\n",
    "        return self.model.predict(np.array([states]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02vCtMwQZpLD",
    "outputId": "fa846b8c-ab2a-4c91-d6f6-2493e64f0a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84, 84, 1), array([0.61239219]))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img[:,:,0]*0.299 + img[:,:,1]*0.587 + img[:,:,2]*0.114; #колориметрия\n",
    "    img = img/255.\n",
    "    img = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "    img = img[18:102, :]\n",
    "    return np.reshape(img, [84, 84, 1])\n",
    "\n",
    "zero_img = np.zeros((210, 105, 3))\n",
    "zero_img[:,:,0] = 130\n",
    "zero_img[:,:,1] = 160\n",
    "zero_img[:,:,2] = 205\n",
    "pp = preprocess(zero_img)\n",
    "pp.shape, pp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LDOwo1dIb7S"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.env = ENV        \n",
    "        self.epsilon = 1\n",
    "        self.buffer = Buffer(10000)\n",
    "        self.DQN = DQN(self.buffer, min_buffer=10000)\n",
    "        self.copy_period = 2000\n",
    "        self.iter = 0\n",
    "        self.eps_step = 1e-6\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.DQN.predict(state)[0])    \n",
    "    \n",
    "    def play_episode(self, num):\n",
    "        observation = self.env.reset()\n",
    "        done = False\n",
    "        states = deque(maxlen=4)\n",
    "        states.append(preprocess(observation))\n",
    "        prev_states = deque(maxlen=4)\n",
    "        total_reward = 0\n",
    "        k = 4\n",
    "        while not done:          \n",
    "            if len(states) < k:\n",
    "                action = self.env.action_space.sample()\n",
    "            else:\n",
    "                action = self.sample_action(states)         \n",
    "\n",
    "            if len(states) > 0:\n",
    "                prev_states.append(states[-1])\n",
    "\n",
    "            observation, reward, done, _ = self.env.step(action)\n",
    "            states.append(preprocess(observation))\n",
    "\n",
    "            if len(states) == k and len(prev_states) == k:\n",
    "                self.buffer.add(list(prev_states), action, reward, list(states), done) # S A R S' A\n",
    "\n",
    "            total_reward += reward\n",
    "            \n",
    "            self.iter += 1\n",
    "            if self.iter % 10 == 0:\n",
    "                self.DQN.train()\n",
    "            self.epsilon = max(0.1, self.epsilon - self.eps_step)\n",
    "            if self.iter % self.copy_period == 0:\n",
    "                self.DQN.copy_weights()\n",
    "        return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtvEh5X-PzWu",
    "outputId": "5052dc00-d76e-4a25-c5f2-e96d706f4092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 21, 21, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 4,046,502\n",
      "Trainable params: 4,046,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "agent.DQN.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wxii6jPtE-GS",
    "outputId": "13733b84-97ce-4d92-f543-70e756ca239f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 >>>> total reward: -20.0\n",
      "Episode 1 >>>> total reward: -21.0\n",
      "Episode 2 >>>> total reward: -19.0\n",
      "Episode 3 >>>> total reward: -21.0\n",
      "Episode 4 >>>> total reward: -20.0\n",
      "Episode 5 >>>> total reward: -20.0\n",
      "Episode 6 >>>> total reward: -19.0\n",
      "Episode 7 >>>> total reward: -21.0\n",
      "Episode 8 >>>> total reward: -21.0\n",
      "Episode 9 >>>> total reward: -20.0\n",
      "Episode 10 >>>> total reward: -21.0\n",
      "Saving the model...\n",
      "Episode 11 >>>> total reward: -21.0\n",
      "Episode 12 >>>> total reward: -21.0\n",
      "Episode 13 >>>> total reward: -21.0\n",
      "Episode 14 >>>> total reward: -21.0\n",
      "Episode 15 >>>> total reward: -21.0\n",
      "Episode 16 >>>> total reward: -18.0\n",
      "Episode 17 >>>> total reward: -19.0\n",
      "Episode 18 >>>> total reward: -18.0\n",
      "Episode 19 >>>> total reward: -20.0\n",
      "Episode 20 >>>> total reward: -20.0\n",
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "s = ENV.reset()\n",
    "\n",
    "NUM_EPISODES = 100000\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "for i in range(NUM_EPISODES):\n",
    "    total_reward = agent.play_episode(i)\n",
    "    print(f\"Episode {i} >>>> total reward:\", total_reward)\n",
    "    if i>0 and i % 10 == 0:\n",
    "        print(\"Saving the model...\")\n",
    "        agent.DQN.model.save(f\"./drive/My Drive/models/pong/pong.{i:6}.hdf5\")\n",
    "        \n",
    "ENV.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nn-17.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
