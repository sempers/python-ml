{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nn-15-chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4Zar4A8jApH",
        "outputId": "df24185c-0956-4563-dc0c-aa0a71a9ca0d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teahym5YPCcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c890ed-f710-44c4-c69d-deb0188a665a"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import sys\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import json\n",
        "np.random.seed(42)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6CU1XVJPCc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae16e40f-3ba0-4db0-c281-716fe5a0585d"
      },
      "source": [
        "conv_df = pd.read_csv(\"./drive/My Drive/data/movie_dialogs_dataset/movie_conversations.txt\", sep=r\" \\+\\+\\+\\$\\+\\+\\+ \", header=None)\n",
        "conv_df.columns = [\"pers1\", \"pers2\", \"movie\", \"replies\"]\n",
        "\n",
        "print(conv_df.head())\n",
        "len(conv_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  pers1 pers2 movie                           replies\n",
            "0    u0    u2    m0  ['L194', 'L195', 'L196', 'L197']\n",
            "1    u0    u2    m0                  ['L198', 'L199']\n",
            "2    u0    u2    m0  ['L200', 'L201', 'L202', 'L203']\n",
            "3    u0    u2    m0          ['L204', 'L205', 'L206']\n",
            "4    u0    u2    m0                  ['L207', 'L208']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paogNT86PCdD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "7a859e89-5446-4c15-ff51-a203c9c244d8"
      },
      "source": [
        "lines_df = pd.read_csv(\"./drive/My Drive/data/movie_dialogs_dataset/movie_lines.txt\", sep=r\" \\+\\+\\+\\$\\+\\+\\+ \", header=None)\n",
        "lines_df.columns = [\"lineid\", \"pers\", \"movie\", \"pers_name\", \"line\"]\n",
        "lines_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lineid</th>\n",
              "      <th>pers</th>\n",
              "      <th>movie</th>\n",
              "      <th>pers_name</th>\n",
              "      <th>line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1045</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>They do not!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1044</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>They do to!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L985</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>I hope so.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L984</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>She okay?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L925</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Let's go.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  lineid pers movie pers_name          line\n",
              "0  L1045   u0    m0    BIANCA  They do not!\n",
              "1  L1044   u2    m0   CAMERON   They do to!\n",
              "2   L985   u0    m0    BIANCA    I hope so.\n",
              "3   L984   u2    m0   CAMERON     She okay?\n",
              "4   L925   u0    m0    BIANCA     Let's go."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXj55lVemMQC"
      },
      "source": [
        "QA_df = pd.DataFrame(columns=[\"q\", \"a\"])\n",
        "for i, row in conv_df.iterrows():\n",
        "    arr = eval(row[\"replies\"])\n",
        "    pers1 = row[\"pers1\"]\n",
        "    pers2 = row[\"pers2\"]\n",
        "    nrow = {'q': None, 'a': None}\n",
        "    for lineid in arr:\n",
        "        line = lines_df.loc[lines_df['lineid'] == lineid].values[0]        \n",
        "        if line is not None:\n",
        "            if line[1] == pers1:\n",
        "                nrow['q'] = line[4]\n",
        "            else:\n",
        "                nrow['a'] = line[4]\n",
        "            if nrow['q'] is not None and nrow['a'] is not None:\n",
        "                QA_df = QA_df.append(nrow, ignore_index=True)\n",
        "                nrow = {'q': None, 'a': None}\n",
        "                if len(QA_df)%100 == 0:\n",
        "                    print(\"Writing \", len(QA_df), \" qa pairs...\")\n",
        "print(len(QA_df))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScnAqXlWqi6b"
      },
      "source": [
        "QA_df.to_csv(\"./drive/My Drive/data/movie_dialogs_dataset/QA.txt\", sep=r\"Â©\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAKN1AQSDx-f",
        "outputId": "c7ef679d-cff4-4495-eeaf-d24ddeffa42f"
      },
      "source": [
        "QA_df = pd.read_csv(\"./drive/My Drive/data/movie_dialogs_dataset/QA.txt\", sep=r\"Â©\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qfDKlJ5EEBt3",
        "outputId": "d780163a-ab36-45b5-bc27-3671f17da37d"
      },
      "source": [
        "QA_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>q</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
              "      <td>Forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
              "      <td>Cameron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The thing is, Cameron -- I'm at the mercy of a...</td>\n",
              "      <td>Seems like she could get a date easy enough...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                  a\n",
              "0           0  ...  Well, I thought we'd start with pronunciation,...\n",
              "1           1  ...  Okay... then how 'bout we try out some French ...\n",
              "2           2  ...                                         Forget it.\n",
              "3           3  ...                                           Cameron.\n",
              "4           4  ...     Seems like she could get a date easy enough...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eniO-xiVfjQq"
      },
      "source": [
        "MIN_LEN = 10\n",
        "MAX_LEN = 100\n",
        "N_VOCAB = 256\n",
        "PAD = \"\\u0016\"\n",
        "START = \"\\u0017\"\n",
        "END = \"\\u0018\"\n",
        "\n",
        "from collections import Counter    \n",
        "\n",
        "#Ð¤Ð¸Ð»ÑÑÑÑÐµÐ¼ ÐºÐ¾ÑÐ¾ÑÐºÐ¸Ðµ Ð¸ Ð´Ð»Ð¸Ð½Ð½ÑÐµ ÑÑÑÐ¾ÐºÐ¸\n",
        "def filter_length(q,a, minlen=MIN_LEN, maxlen=MAX_LEN):\n",
        "    q1 = []\n",
        "    a1 = []\n",
        "    for i in range(len(q)):\n",
        "        qi = q[i].replace(\"<u>\", \"\").replace(\"</u>\", \"\").replace(\"<b>\", \"\").replace(\"</b>\", \"\").replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\"<i>\", \"\").replace(\"</i>\", \"\")\n",
        "        ai = a[i].replace(\"<u>\", \"\").replace(\"</u>\", \"\").replace(\"<b>\", \"\").replace(\"</b>\", \"\").replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\"<i>\", \"\").replace(\"</i>\", \"\")\n",
        "        if len(qi) >= minlen and len(qi)<=maxlen and len(ai)>=minlen and len(ai)<=maxlen:\n",
        "            q1.append(qi)\n",
        "            a1.append(ai)\n",
        "    return q1, a1\n",
        "\n",
        "def gen_vocabs(lines, vocab = None, log_vocab=False):    \n",
        "    counter = Counter()\n",
        "    for line in lines:\n",
        "        chars = [c for c in line]\n",
        "        counter.update(chars)\n",
        "    #Ð³ÐµÐ½ÐµÑÐ¸ÑÑÐµÐ¼ ÑÐ»Ð¾Ð²Ð°ÑÑ, ÐµÑÐ»Ð¸ Ð½ÐµÐ¾Ð±ÑÐ¾Ð´Ð¸Ð¼Ð¾\n",
        "    if vocab is None:\n",
        "        vocab  = sorted([x for (x, count) in counter.most_common(N_VOCAB-3)])\n",
        "        if log_vocab:\n",
        "            with open(\"./vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "                for k,v in counter.most_common(N_VOCAB-3):\n",
        "                    f.write(\"%s : %d\\n\" % (k, v))\n",
        "        vocab = ([PAD, START, END] + vocab)\n",
        "        vocab = {w: idx for idx, w in enumerate(vocab)}\n",
        "        vocab_inverse = {idx: w for w, idx in vocab.items()}\n",
        "    \n",
        "    return vocab, vocab_inverse\n",
        "\n",
        "def to_sequence(line):\n",
        "    return [vocab[c] if c in vocab else vocab[PAD] for c in line] + [2] #END\n",
        "\n",
        "def gen_sequences(lines):\n",
        "    return [to_sequence(line) for line in lines]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py9GYiiODttZ",
        "outputId": "b4809ac9-ee41-4998-ed14-81cafdae900c"
      },
      "source": [
        "Q = QA_df['q'].values\n",
        "A = QA_df['a'].values\n",
        "\n",
        "Q, A = filter_length(Q, A, minlen=10, maxlen=60)\n",
        "\n",
        "vocab, vocab_inverse = gen_vocabs(Q+A)\n",
        "Qt = gen_sequences(Q)\n",
        "At = gen_sequences(A)\n",
        "\n",
        "len(vocab), len(Qt), len(At), Qt[:1], At[:1]\n",
        "#ÑÐ»Ð¾Ð²Ð°ÑÑ Ð´Ð»Ð¸Ð½Ð¾Ð¹ Ð²ÑÐµÐ³Ð¾ 96, Ð¿ÑÐ¸ÑÐ¾Ð¼ Ð¼Ñ ÑÐ¾ÑÑÐ°Ð½ÑÐµÐ¼ ÐºÐµÐ¹Ñ, Ð½Ðµ Ð´ÐµÐ»Ð°ÐµÐ¼ .lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96,\n",
              " 53020,\n",
              " 53020,\n",
              " [[41,\n",
              "   79,\n",
              "   83,\n",
              "   72,\n",
              "   15,\n",
              "   4,\n",
              "   73,\n",
              "   70,\n",
              "   4,\n",
              "   79,\n",
              "   78,\n",
              "   76,\n",
              "   89,\n",
              "   4,\n",
              "   87,\n",
              "   69,\n",
              "   4,\n",
              "   67,\n",
              "   79,\n",
              "   85,\n",
              "   76,\n",
              "   68,\n",
              "   4,\n",
              "   70,\n",
              "   73,\n",
              "   78,\n",
              "   68,\n",
              "   4,\n",
              "   45,\n",
              "   65,\n",
              "   84,\n",
              "   4,\n",
              "   65,\n",
              "   4,\n",
              "   66,\n",
              "   79,\n",
              "   89,\n",
              "   70,\n",
              "   82,\n",
              "   73,\n",
              "   69,\n",
              "   78,\n",
              "   68,\n",
              "   17,\n",
              "   17,\n",
              "   17,\n",
              "   2]],\n",
              " [[46,\n",
              "   69,\n",
              "   84,\n",
              "   4,\n",
              "   77,\n",
              "   69,\n",
              "   4,\n",
              "   83,\n",
              "   69,\n",
              "   69,\n",
              "   4,\n",
              "   87,\n",
              "   72,\n",
              "   65,\n",
              "   84,\n",
              "   4,\n",
              "   43,\n",
              "   4,\n",
              "   67,\n",
              "   65,\n",
              "   78,\n",
              "   4,\n",
              "   68,\n",
              "   79,\n",
              "   17,\n",
              "   2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jXnF7_tPCdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1029bf3a-b2ba-4fdd-8fc8-9abca899519f"
      },
      "source": [
        "MAX_LEN = 1000\n",
        "N_LSTM = 512\n",
        "N_EMBED = 32\n",
        "N_VOCAB = len(vocab)\n",
        "\n",
        "import keras.layers as L\n",
        "\n",
        "def build_model():\n",
        "    X = L.Input(shape=(None,))\n",
        "    D = L.Input(shape=(None,))\n",
        "    e = L.Embedding(N_VOCAB, N_EMBED, mask_zero=True)(X)\n",
        "    d = L.Embedding(N_VOCAB, N_EMBED, mask_zero=True)(D)\n",
        "\n",
        "    enc, fh, fc, bh, bc = L.Bidirectional(L.LSTM(units=N_LSTM, return_sequences=True, return_state=True, dropout=0.1))(e)   \n",
        "    h = L.Concatenate()([fh, bh])\n",
        "    c = L.Concatenate()([fc, bc])\n",
        "\n",
        "    #decoder\n",
        "    dec = L.LSTM(N_LSTM*2, return_sequences=True, dropout=0.1)(d, initial_state=[h, c])\n",
        "    \n",
        "    #attention\n",
        "    att = L.Attention(use_scale=True)([dec, enc])                                      \n",
        "    out = L.Concatenate()([att, dec])\n",
        "\n",
        "    #Ð²ÑÑÐ¾Ð´Ð½ÑÐµ ÑÐ»Ð¾Ð¸ \n",
        "    d = L.TimeDistributed(L.Dense(2048, activation='relu'))(out)\n",
        "    d = L.Dropout(0.1)(d)\n",
        "    Y = L.TimeDistributed(L.Dense(N_VOCAB, activation='softmax'))(d)\n",
        "    return keras.models.Model(inputs=[X,D], outputs=Y)\n",
        "    \n",
        "model = build_model()\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_23\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_22 (Embedding)        (None, None, 32)     3072        input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional [(None, None, 1024), 2232320     embedding_22[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_23 (Embedding)        (None, None, 32)     3072        input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 1024)         0           bidirectional_11[0][1]           \n",
            "                                                                 bidirectional_11[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 1024)         0           bidirectional_11[0][2]           \n",
            "                                                                 bidirectional_11[0][4]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm_23 (LSTM)                  (None, None, 1024)   4329472     embedding_23[0][0]               \n",
            "                                                                 concatenate_33[0][0]             \n",
            "                                                                 concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "attention_11 (Attention)        (None, None, 1024)   1           lstm_23[0][0]                    \n",
            "                                                                 bidirectional_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, None, 2048)   0           attention_11[0][0]               \n",
            "                                                                 lstm_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_23 (TimeDistri (None, None, 2048)   4196352     concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, None, 2048)   0           time_distributed_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_24 (TimeDistri (None, None, 96)     196704      dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 10,960,993\n",
            "Trainable params: 10,960,993\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0d8EegRPCdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ef9666-eeca-4331-8e9d-58c210718f80"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "N_VOCAB = len(vocab)\n",
        "\n",
        "def to_text(seq):\n",
        "    return \"\".join([vocab_inverse[idx] for idx in seq])\n",
        "\n",
        "def to_matrix(texts, maxlen=0):\n",
        "    seqs = texts\n",
        "    if maxlen == 0:\n",
        "        maxlen = min(MAX_LEN, max(list(map(len, seqs))))\n",
        "    return keras.preprocessing.sequence.pad_sequences(seqs, maxlen=maxlen, dtype='int32', padding='post', truncating='post', value=0)\n",
        "\n",
        "import random\n",
        "\n",
        "def shuffleXY(x, y):\n",
        "    Z = list(zip(x, y))\n",
        "    random.shuffle(Z)\n",
        "    return zip(*Z)\n",
        "\n",
        "def train_gen(x, y):\n",
        "    offset = 0\n",
        "    count = BATCH_SIZE\n",
        "    while True:\n",
        "        xt = to_matrix(x[offset:offset+count], 0)\n",
        "        yt = to_matrix(y[offset:offset+count], 0)\n",
        "        dt = np.zeros_like(yt)\n",
        "        dt[:, 1:] = yt[:,:-1]\n",
        "        dt[:, 0] = 1 # START\n",
        "        yield [xt, dt], yt\n",
        "        offset += count\n",
        "        if offset >= len(x)//BATCH_SIZE*BATCH_SIZE:\n",
        "            offset = 0\n",
        "            \n",
        "def _schedule(epoch, lr):\n",
        "    if epoch < 3:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.97**epoch\n",
        "\n",
        "def mend_proba(p):\n",
        "    p = np.log(p)\n",
        "    p[0] = -100\n",
        "    p = np.exp(p)/np.sum(np.exp(p))\n",
        "    return p\n",
        "\n",
        "def sample(proba, temp=1.0, mend=False, method='choice'):\n",
        "    if mend:\n",
        "        proba = mend_proba(proba)\n",
        "    if temp != 1.0:\n",
        "        proba = np.log(proba) / temp\n",
        "        proba = np.exp(proba)/np.sum(np.exp(proba))    \n",
        "    if method == 'choice':\n",
        "        return np.random.choice(len(proba), p=proba)\n",
        "    elif method == 'multinomial':\n",
        "        proba *= 0.9999\n",
        "        return np.argmax(np.random.multinomial(1, proba, 1))\n",
        "\n",
        "MAX_LEN = 100\n",
        "\n",
        "def get_generation(seed=\"\", temp=1.0, mend=False, method='choice'):\n",
        "    seq = [1] # <START>\n",
        "    x = np.array([to_sequence(seed)])\n",
        "    idx = 0\n",
        "    while len(seq) < MAX_LEN:\n",
        "        d = np.array([seq])\n",
        "        y = model.predict([x,d])\n",
        "        p = y[0][-1]\n",
        "        idx = sample(p, temp=temp, mend=mend, method=method)\n",
        "        seq.append(idx)\n",
        "        if idx in [0,2]: #<PAD><END>\n",
        "            break\n",
        "    return to_text(seq[1:-1])    \n",
        "\n",
        "def generate_epoch_end(e, logs):\n",
        "    print(\"\\n\\nEpoch = \", e+1, \", Sample generation = -Hello! How are you? -\" + get_generation(seed=\"Hello! How are you?\") + \"\\n\")\n",
        "\n",
        "def train_model(initial_epoch, n_epochs, train_gen):\n",
        "    model.fit(train_gen, epochs=n_epochs, steps_per_epoch=len(Qt)//BATCH_SIZE,  initial_epoch=initial_epoch, \n",
        "                callbacks=[\n",
        "                  tf.keras.callbacks.LearningRateScheduler(_schedule),\n",
        "                  tf.keras.callbacks.ModelCheckpoint(filepath='./model.{epoch:03d}.hdf5'),\n",
        "                  tf.keras.callbacks.LambdaCallback(on_epoch_end=generate_epoch_end)\n",
        "              ])\n",
        "\n",
        "len(Qt), len(At)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53020, 53020)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G_uqNNoPCdf"
      },
      "source": [
        "opt = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNBwwdrsPCdj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a80c4d6-abce-422f-dde6-e62e7fb4c187"
      },
      "source": [
        "train_model(0, 30, train_gen(Qt, At))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 1.5610 - accuracy: 0.2179\n",
            "\n",
            "Epoch =  1 , Sample generation = -Hello! How are you? -I dat son mis?\n",
            "\n",
            "827/827 [==============================] - 66s 80ms/step - loss: 1.5610 - accuracy: 0.2179\n",
            "Epoch 2/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.3355\n",
            "\n",
            "Epoch =  2 , Sample generation = -Hello! How are you? -I mily Wace ce warey duthe purill, do> men.\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 1.2418 - accuracy: 0.3355\n",
            "Epoch 3/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 1.1396 - accuracy: 0.3809\n",
            "\n",
            "Epoch =  3 , Sample generation = -Hello! How are you? -Nag It there intsy sre sis?\n",
            "\n",
            "827/827 [==============================] - 59s 71ms/step - loss: 1.1396 - accuracy: 0.3809\n",
            "Epoch 4/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 1.0647 - accuracy: 0.4166\n",
            "\n",
            "Epoch =  4 , Sample generation = -Hello! How are you? -Geathed. Jill there-ne wim timna?\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 1.0647 - accuracy: 0.4166\n",
            "Epoch 5/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 1.0076 - accuracy: 0.4439\n",
            "\n",
            "Epoch =  5 , Sample generation = -Hello! How are you? -Ho poull them bossine, ure... So you wear it?\n",
            "\n",
            "827/827 [==============================] - 60s 72ms/step - loss: 1.0076 - accuracy: 0.4439\n",
            "Epoch 6/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.9650 - accuracy: 0.4646\n",
            "\n",
            "Epoch =  6 , Sample generation = -Hello! How are you? -Jeybcyour Ker forsehing a lithlh ofr ifyer rave <u> redalia...\n",
            "\n",
            "827/827 [==============================] - 60s 73ms/step - loss: 0.9650 - accuracy: 0.4646\n",
            "Epoch 7/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.9332 - accuracy: 0.4800\n",
            "\n",
            "Epoch =  7 , Sample generation = -Hello! How are you? -Him anoaK madn of courlifat E0\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.9332 - accuracy: 0.4800\n",
            "Epoch 8/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.4916\n",
            "\n",
            "Epoch =  8 , Sample generation = -Hello! How are you? -Foonn, brare.\n",
            "\n",
            "827/827 [==============================] - 59s 71ms/step - loss: 0.9092 - accuracy: 0.4916\n",
            "Epoch 9/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.5003\n",
            "\n",
            "Epoch =  9 , Sample generation = -Hello! How are you? -It's it.  I'm anyead wark. O-\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.8912 - accuracy: 0.5003\n",
            "Epoch 10/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.5069\n",
            "\n",
            "Epoch =  10 , Sample generation = -Hello! How are you? -Don't crime an mean.  Ohay.\n",
            "\n",
            "827/827 [==============================] - 59s 71ms/step - loss: 0.8775 - accuracy: 0.5069\n",
            "Epoch 11/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8677 - accuracy: 0.5116\n",
            "\n",
            "Epoch =  11 , Sample generation = -Hello! How are you? -Ahe what I just to ligs you?\n",
            "\n",
            "827/827 [==============================] - 59s 71ms/step - loss: 0.8677 - accuracy: 0.5116\n",
            "Epoch 12/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8603 - accuracy: 0.5157\n",
            "\n",
            "Epoch =  12 , Sample generation = -Hello! How are you? -There isno sulls offtonioge of I do it.\n",
            "\n",
            "827/827 [==============================] - 60s 72ms/step - loss: 0.8603 - accuracy: 0.5157\n",
            "Epoch 13/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8553 - accuracy: 0.5180\n",
            "\n",
            "Epoch =  13 , Sample generation = -Hello! How are you? -Stild'd, you really here her.\n",
            "\n",
            "827/827 [==============================] - 59s 71ms/step - loss: 0.8553 - accuracy: 0.5180\n",
            "Epoch 14/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8518 - accuracy: 0.5198\n",
            "\n",
            "Epoch =  14 , Sample generation = -Hello! How are you? -...Godry got oft with a com-utny frome.\n",
            "\n",
            "827/827 [==============================] - 60s 72ms/step - loss: 0.8518 - accuracy: 0.5198\n",
            "Epoch 15/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8495 - accuracy: 0.5209\n",
            "\n",
            "Epoch =  15 , Sample generation = -Hello! How are you? -No. That's on light anare.\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.8495 - accuracy: 0.5209\n",
            "Epoch 16/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.5219\n",
            "\n",
            "Epoch =  16 , Sample generation = -Hello! How are you? -Where's your nimers schomel?\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.8477 - accuracy: 0.5219\n",
            "Epoch 17/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8468 - accuracy: 0.5223\n",
            "\n",
            "Epoch =  17 , Sample generation = -Hello! How are you? -I've just my noCto do shicmy?\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.8468 - accuracy: 0.5223\n",
            "Epoch 18/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8461 - accuracy: 0.5226\n",
            "\n",
            "Epoch =  18 , Sample generation = -Hello! How are you? -Do Adarif.R I think at it!\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.8461 - accuracy: 0.5226\n",
            "Epoch 19/30\n",
            "827/827 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.5229\n",
            "\n",
            "Epoch =  19 , Sample generation = -Hello! How are you? -I was can tho tonsor-\n",
            "\n",
            "827/827 [==============================] - 59s 72ms/step - loss: 0.8458 - accuracy: 0.5229\n",
            "Epoch 20/30\n",
            "749/827 [==========================>...] - ETA: 5s - loss: 0.8451 - accuracy: 0.5226"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-21c875e85ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-d786cf4b1f1c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(initial_epoch, n_epochs, train_gen)\u001b[0m\n\u001b[1;32m     82\u001b[0m                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model.{epoch:03d}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_epoch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m               ])\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "NpCKEb2q_t4F",
        "outputId": "95b585ea-e6ea-4c4f-9c88-84902df52734"
      },
      "source": [
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "train_model(30, 50, train_gen(Qt, At))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 31/50\n",
            "1656/1656 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.6140\n",
            "\n",
            "Epoch =  31 , Sample generation = -Hello! How are you? -Yesy! Hustenyul!\n",
            "\n",
            "1656/1656 [==============================] - 94s 57ms/step - loss: 0.6915 - accuracy: 0.6140\n",
            "Epoch 32/50\n",
            "1656/1656 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.6220\n",
            "\n",
            "Epoch =  32 , Sample generation = -Hello! How are you? -How do you know who the man you ton?\n",
            "\n",
            "1656/1656 [==============================] - 87s 53ms/step - loss: 0.6750 - accuracy: 0.6220\n",
            "Epoch 33/50\n",
            "1656/1656 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.6245\n",
            "\n",
            "Epoch =  33 , Sample generation = -Hello! How are you? -Sigh the clazy?\n",
            "\n",
            "1656/1656 [==============================] - 86s 52ms/step - loss: 0.6695 - accuracy: 0.6245\n",
            "Epoch 34/50\n",
            "1656/1656 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.6258\n",
            "\n",
            "Epoch =  34 , Sample generation = -Hello! How are you? -Thank you.\n",
            "\n",
            "1656/1656 [==============================] - 86s 52ms/step - loss: 0.6674 - accuracy: 0.6258\n",
            "Epoch 35/50\n",
            "1656/1656 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.6262\n",
            "\n",
            "Epoch =  35 , Sample generation = -Hello! How are you? -Then found one off of the hands! How did you tell you?\n",
            "\n",
            "1656/1656 [==============================] - 88s 53ms/step - loss: 0.6665 - accuracy: 0.6262\n",
            "Epoch 36/50\n",
            " 370/1656 [=====>........................] - ETA: 1:06 - loss: 0.6632 - accuracy: 0.6261"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-ef30a5a80f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-78-d2dddc215089>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(initial_epoch, n_epochs, train_gen)\u001b[0m\n\u001b[1;32m     80\u001b[0m                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model.{epoch:03d}.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_epoch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m               ])\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNIAq3LDj-FS",
        "outputId": "3b8e3f4e-6a79-4f42-fe09-21c7d7a4c08b"
      },
      "source": [
        "model.reset_states()\n",
        "\n",
        "seed = \"Where is the money?\"\n",
        "\n",
        "print(\"Dialog question: \", seed)\n",
        "print(\"Dialog possible answers:\")\n",
        "\n",
        "for i in range(20):\n",
        "    print(str(i+1)+'.', get_generation(seed))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dialog question:  Where is the money?\n",
            "Dialog possible answers:\n",
            "1. Yes, they dign't even tund to be all right.\n",
            "2. What's up, Bamem...\n",
            "3. ...do you think I'm very suspised.\n",
            "4. It's all digler's around.  Louis?\n",
            "5. What's the point?\n",
            "6. Flack in your par.\n",
            "7. What'll you take any time?  Teleï¿½non, and I can't find it.\n",
            "8. Oh ...-never hands a maroon car.\n",
            "9. Yes.  From the bardrocn dick here!\n",
            "10. I think I'm not going to speak about this brave...\n",
            "11. Shrapminel? How go you want going to get in?\n",
            "12. It's Hine.\n",
            "13. Guess she talked to Maxle Party.\n",
            "14. You don't know...\n",
            "15. This is good news...\n",
            "16. I thought it's the justom, fester. There are ode what?..\n",
            "17. Well being Mictor?\n",
            "18. You can't Marter, Nick I come --\n",
            "19. Who's the river reaw things agend?\n",
            "20. Will you finally sue doing it?\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}