{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг веб-страниц\n",
    "\n",
    "Кажется, самое легкое задание из всего финального проекта, если вы программист."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\bin\\anaconda3\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\bin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.9.3)\n",
      "Requirement already satisfied: lxml in c:\\bin\\anaconda3\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: requests in c:\\bin\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\bin\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\bin\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\bin\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\bin\\anaconda3\\lib\\site-packages (from requests) (2019.9.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install lxml\n",
    "!pip install requests\n",
    "\n",
    "#В целом не нужно, т.к. все модули входят в анаконду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL1 = \"https://en.wikipedia.org/wiki/Bias-variance_tradeoff\"\n",
    "URL2 = \"https://en.wikipedia.org/wiki/Category:Machine_learning_algorithms\"\n",
    "\n",
    "r1 = requests.get(URL1)\n",
    "r2 = requests.get(URL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Motivation',\n",
       "  'Bias–variance decomposition of squared error',\n",
       "  'Application to regression',\n",
       "  'Application to classification',\n",
       "  'Application to reinforcement learning',\n",
       "  'Approaches',\n",
       "  'Application to human learning',\n",
       "  'See also',\n",
       "  'References'],\n",
       " ['Algorithms of Oppression',\n",
       "  'Almeida–Pineda recurrent backpropagation',\n",
       "  'Backpropagation',\n",
       "  'Bioz',\n",
       "  'Bootstrap aggregating',\n",
       "  'Cancer Likelihood in Plasma',\n",
       "  'CN2 algorithm',\n",
       "  'Constructing skill trees',\n",
       "  'User:CrizCraig/sandbox',\n",
       "  'Deep reinforcement learning',\n",
       "  'Dehaene–Changeux model',\n",
       "  'Diffusion map',\n",
       "  'Dominance-based rough set approach',\n",
       "  'Dynamic time warping',\n",
       "  'Elastic net regularization',\n",
       "  'Error-driven learning',\n",
       "  'Evolutionary multimodal optimization',\n",
       "  'Expectation–maximization algorithm',\n",
       "  'Extremal Ensemble Learning',\n",
       "  'FastICA',\n",
       "  'Forward–backward algorithm',\n",
       "  'GeneRec',\n",
       "  'Genetic Algorithm for Rule Set Production',\n",
       "  'Growing self-organizing map',\n",
       "  'Hyper basis function network',\n",
       "  'IDistance',\n",
       "  'K-nearest neighbors algorithm',\n",
       "  'Kernel methods for vector output',\n",
       "  'Kernel principal component analysis',\n",
       "  'Label propagation algorithm',\n",
       "  'Lasso (statistics)',\n",
       "  'Leabra',\n",
       "  'Linde–Buzo–Gray algorithm',\n",
       "  'Local outlier factor',\n",
       "  'Logic learning machine',\n",
       "  'LogitBoost',\n",
       "  'Loss functions for classification',\n",
       "  'Manifold alignment',\n",
       "  'Minimum redundancy feature selection',\n",
       "  'Mixture of experts',\n",
       "  'Multiple kernel learning',\n",
       "  'Non-negative matrix factorization',\n",
       "  'Online machine learning',\n",
       "  'Out-of-bag error',\n",
       "  'Prefrontal cortex basal ganglia working memory',\n",
       "  'Prototype methods',\n",
       "  'PVLV',\n",
       "  'Q-learning',\n",
       "  'Quadratic unconstrained binary optimization',\n",
       "  'Query-level feature',\n",
       "  'Quickprop',\n",
       "  'Radial basis function network',\n",
       "  'Randomized weighted majority algorithm',\n",
       "  'Repeated incremental pruning to produce error reduction (RIPPER)',\n",
       "  'Rprop',\n",
       "  'Rule-based machine learning',\n",
       "  'Skill chaining',\n",
       "  'Sparse PCA',\n",
       "  'State–action–reward–state–action',\n",
       "  'Stochastic gradient descent',\n",
       "  'Structured kNN',\n",
       "  'T-distributed stochastic neighbor embedding',\n",
       "  'Triplet loss',\n",
       "  'Wake-sleep algorithm',\n",
       "  'Weighted majority algorithm (machine learning)',\n",
       "  'Zero-shot learning'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вариант 1 - достаем при помощи lxml, лично я больше люблю этот парсер за XPath\n",
    "tree = lxml.etree.fromstring(r1.text, lxml.etree.HTMLParser())\n",
    "list1 = [x.text for x in tree.findall(\".//h2/span[@class='mw-headline']\")]\n",
    "\n",
    "tree = lxml.etree.fromstring(r2.text, lxml.etree.HTMLParser())\n",
    "list2 = [x.text for x in tree.findall(\".//div[@class='mw-category']//li/a\")]\n",
    "\n",
    "list1, list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Motivation',\n",
       "  'Bias–variance decomposition of squared error',\n",
       "  'Application to regression',\n",
       "  'Application to classification',\n",
       "  'Application to reinforcement learning',\n",
       "  'Approaches',\n",
       "  'Application to human learning',\n",
       "  'See also',\n",
       "  'References'],\n",
       " ['Adagrad',\n",
       "  'Algorithms of Oppression',\n",
       "  'Almeida–Pineda recurrent backpropagation',\n",
       "  'Backpropagation',\n",
       "  'Bioz',\n",
       "  'Bootstrap aggregating',\n",
       "  'Cancer Likelihood in Plasma',\n",
       "  'CN2 algorithm',\n",
       "  'Constructing skill trees',\n",
       "  'User:CrizCraig/sandbox',\n",
       "  'Deep reinforcement learning',\n",
       "  'Dehaene–Changeux model',\n",
       "  'Diffusion map',\n",
       "  'Dominance-based rough set approach',\n",
       "  'Dynamic time warping',\n",
       "  'Elastic net regularization',\n",
       "  'Error-driven learning',\n",
       "  'Evolutionary multimodal optimization',\n",
       "  'Expectation–maximization algorithm',\n",
       "  'Extremal Ensemble Learning',\n",
       "  'FastICA',\n",
       "  'Forward–backward algorithm',\n",
       "  'GeneRec',\n",
       "  'Genetic Algorithm for Rule Set Production',\n",
       "  'Growing self-organizing map',\n",
       "  'Hyper basis function network',\n",
       "  'IDistance',\n",
       "  'K-nearest neighbors algorithm',\n",
       "  'Kernel methods for vector output',\n",
       "  'Kernel principal component analysis',\n",
       "  'Label propagation algorithm',\n",
       "  'Lasso (statistics)',\n",
       "  'Leabra',\n",
       "  'Linde–Buzo–Gray algorithm',\n",
       "  'Local outlier factor',\n",
       "  'Logic learning machine',\n",
       "  'LogitBoost',\n",
       "  'Loss functions for classification',\n",
       "  'Manifold alignment',\n",
       "  'Minimum redundancy feature selection',\n",
       "  'Mixture of experts',\n",
       "  'Multiple kernel learning',\n",
       "  'Non-negative matrix factorization',\n",
       "  'Online machine learning',\n",
       "  'Out-of-bag error',\n",
       "  'Prefrontal cortex basal ganglia working memory',\n",
       "  'Prototype methods',\n",
       "  'PVLV',\n",
       "  'Q-learning',\n",
       "  'Quadratic unconstrained binary optimization',\n",
       "  'Query-level feature',\n",
       "  'Quickprop',\n",
       "  'Radial basis function network',\n",
       "  'Randomized weighted majority algorithm',\n",
       "  'Repeated incremental pruning to produce error reduction (RIPPER)',\n",
       "  'Rprop',\n",
       "  'Rule-based machine learning',\n",
       "  'Skill chaining',\n",
       "  'Sparse PCA',\n",
       "  'State–action–reward–state–action',\n",
       "  'Stochastic gradient descent',\n",
       "  'Structured kNN',\n",
       "  'T-distributed stochastic neighbor embedding',\n",
       "  'Triplet loss',\n",
       "  'Wake-sleep algorithm',\n",
       "  'Weighted majority algorithm (machine learning)',\n",
       "  'Zero-shot learning'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Вариант 2, BEAUTIFUL SOUP\n",
    "soup = BeautifulSoup(r1.text, \"html.parser\")\n",
    "list1 = [x.text for x in soup.select(\"h2 span.mw-headline\")]\n",
    "soup = BeautifulSoup(r2.text, \"html.parser\")\n",
    "list2 = [x.text for x in soup.select(\"div.mw-category li a\")]\n",
    "\n",
    "list1, list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание закончено, спасибо за внимание!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
